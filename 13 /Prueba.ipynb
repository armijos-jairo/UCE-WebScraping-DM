{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGvCH1Oy1cDKOVmIibc0m5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armijos-jairo/UCE-WebScraping-DM/blob/main/13%20/Prueba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACCIÓN DE DATOS\n",
        "Autor: \"Jairo Armijos\"\n",
        "Fecha: \"19/12/2023\"\n",
        "Título: \"Extracción de datos de la Web (Scrapy)\"\n",
        "Tema: \"Clasificación de desempeño de artículos científicos para universidades del mundo\""
      ],
      "metadata": {
        "id": "pgN5Mq2AMm_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de las librerias o dependencias necesarias\n",
        "!pip install beautifulsoup4 requests pandas"
      ],
      "metadata": {
        "id": "P0lETSgMM9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencias de carga\n",
        "import json # Modulo para trabajar con archivos JSON\n",
        "import requests # Libreria para hacer peticiones HTTP\n",
        "import pandas as pd # Libreria para procesar datos, proporciona funciones para analíticas\n",
        "from bs4 import BeautifulSoup as bs # Extraer información de paginas web"
      ],
      "metadata": {
        "id": "8LQURTmnM809"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que convierte una lista de elementos en un dataframe de pandas\n",
        "def rowsToDataFrame(rows):\n",
        "    df = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "    return df"
      ],
      "metadata": {
        "id": "rd8KRIqjM4EO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yg6KLXBAMibZ"
      },
      "outputs": [],
      "source": [
        "# Función para extraer los datos de una tabla HTML\n",
        "def processTableData(tbl):\n",
        "    rows = []\n",
        "    for child in tbl.find('tbody').children: # Itera los items internos de la tabla [<tr>]\n",
        "        row = []\n",
        "        for td in child: # Itera los items internos de la tabla [<td>]\n",
        "            try:\n",
        "                item = td.text.replace('\\n', '') # Recupera el texto del elemento [<td>]\n",
        "                if item:\n",
        "                    row.append(item) # Agrega cada elemento de la fila\n",
        "            except:\n",
        "                continue\n",
        "        if len(row) > 0:\n",
        "            rows.append(row) # Agrega todos los campos de una fila de la tabla\n",
        "    print(rows)\n",
        "    return rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer la data de la URL y procesar el contenido HTML\n",
        "def processDataHTML(data):\n",
        "    soup = bs(data['sections'][1]['text'], 'html.parser') # Recupera el item del JSON y lo convierte en contenido HTML\n",
        "    tbl = soup.find_all('table')[0] # Recupera la tabla del contenido HTML\n",
        "    # print(tbl.prettify())\n",
        "    tblRows = processTableData(tbl) # Ejecuta la función para procesar el contenido de la Tabla\n",
        "    return tblRows"
      ],
      "metadata": {
        "id": "Un3yX3LUMyBE"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}